{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполните данные о необходимых переменных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Today = '29/02/24'\n",
    "Mounth = 'Feb'\n",
    "\n",
    "Group = 'SUEK'\n",
    "# Group = 'EUROCHEM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "day = pd.to_datetime(Today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-03-27_SUEK_SAP_Debt_Feb.xlsx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output_file = \"_\".join([str(date.today()), Group, 'SAP', 'Debt', f'{Mounth}.xlsx'])\n",
    "Sheet_in_output_file = 'Debt'\n",
    "Output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открываю следующие файлы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\KlimovaAnnaA\\\\Documents\\\\MyFiles\\\\Projects\\\\OCP\")\n",
    "from Defs import merge_SalesUnits\n",
    "from Defs import merge_Mapping\n",
    "from Defs import Period\n",
    "from Defs import new_list\n",
    "from Defs import export_from_RISKCUSTOM\n",
    "from Defs import add_in_currency_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:78: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"SELECT * FROM \"RISKACCESS\".\"sapPositionArrears\" WHERE \"reportDate\" = TO_DATE('{Today}', 'DD/MM/YY') AND \"productType\" in (130,131,132,133)\"\"\"\n",
    "data_export = export_from_RISKCUSTOM(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15312\\3368282357.py:6: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  'businessPartnerName', 'positionCurrency', 'termEnd']).agg({'purchaseValueDisplayCurrency' : sum,\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_15312\\3368282357.py:6: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  'businessPartnerName', 'positionCurrency', 'termEnd']).agg({'purchaseValueDisplayCurrency' : sum,\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:78: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:109: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[f'Coef_to_{CCY_to}'] = df[col_with_CCY].replace(coef_dict)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# data_Debt = data_export.loc[data_export['productTypeName'].isin(['Транш по займам', 'Транш по кредитам'])].reset_index(drop=True)\n",
    "\n",
    "# data_Debt = data_Debt.groupby(['companyName', 'relationshipPartner',\n",
    "#        'businessPartnerName', 'positionCurrency', 'termEnd']).agg({'purchaseValueDisplayCurrency' : sum,\n",
    "#                                                                           'purchaseValuePositionCurrency' : sum}).reset_index()\n",
    "\n",
    "# data_Debt['purchaseValuePositionCurrency'] = data_Debt['purchaseValuePositionCurrency'] * np.sign(data_Debt['purchaseValueDisplayCurrency'])\n",
    "# data_Debt = add_in_currency_column(data_Debt, col_with_CCY='positionCurrency', col_with_VAL='purchaseValuePositionCurrency', day_for_export=\"29/02/24\", CCY_to='USD')\n",
    "\n",
    "# data_Debt = data_Debt.rename(columns={\"businessPartnerName\": \"Counterparty\", \"companyName\": \"Entity\", \"positionCurrency\": \"Currency\", \"purchaseValuePositionCurrency\": \"amoutn_outstanding\", \"in_USD\": \"amount_USD_eq\", 'purchaseValuePositionCurrency_in_USD':'amount_USD_eq'}).reset_index(drop=True)\n",
    "\n",
    "# data_Debt['Entity_code'] = merge_Mapping(data_Debt, col='Entity')\n",
    "# data_Debt['Entity_group'] = merge_SalesUnits(data_Debt, col='Entity_code', merge_col='ocpSegment')\n",
    "# data_Debt['Counterparty_code'] = merge_Mapping(data_Debt, col='Counterparty')\n",
    "# data_Debt['Counterparty_Group'] = merge_SalesUnits(data_Debt, col='Counterparty_code', merge_col='ocpSegment')\n",
    "\n",
    "# data_Debt = Period(data_Debt, day_for_count=Today, col_with_date='termEnd')\n",
    "\n",
    "# data_Debt['Holding'] = merge_SalesUnits(data_Debt, col='Entity_code', merge_col='holding')\n",
    "# # data_Debt = data_Debt.query('Holding == @Group').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_8776\\151507374.py:7: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  data_Debt = data_Debt.pivot_table(index=['Entity', 'relationshipPartner', 'Counterparty', 'accountAssignmentLinkName', 'Currency', 'termEnd'], values=['purchaseValueDisplayCurrency', 'amoutn_outstanding'], aggfunc={'purchaseValueDisplayCurrency': sum, 'amoutn_outstanding': sum}).reset_index()\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_8776\\151507374.py:7: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  data_Debt = data_Debt.pivot_table(index=['Entity', 'relationshipPartner', 'Counterparty', 'accountAssignmentLinkName', 'Currency', 'termEnd'], values=['purchaseValueDisplayCurrency', 'amoutn_outstanding'], aggfunc={'purchaseValueDisplayCurrency': sum, 'amoutn_outstanding': sum}).reset_index()\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:78: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:109: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[f'Coef_to_{CCY_to}'] = df[col_with_CCY].replace(coef_dict)\n"
     ]
    }
   ],
   "source": [
    "data_Debt = data_export.loc[data_export['productTypeName'].isin(['Транш по займам', 'Транш по кредитам'])].reset_index(drop=True)\n",
    "\n",
    "data_Debt = data_Debt.rename(columns={\"businessPartnerName\": \"Counterparty\", \"companyName\": \"Entity\", \"positionCurrency\": \"Currency\", \"purchaseValuePositionCurrency\": \"amoutn_outstanding\"}).reset_index(drop=True)\n",
    "data_Debt.amoutn_outstanding = data_Debt.amoutn_outstanding.abs()\n",
    "\n",
    "data_Debt['termEnd'] = data_Debt['termEnd'].fillna('_')\n",
    "data_Debt = data_Debt.pivot_table(index=['Entity', 'relationshipPartner', 'Counterparty', 'accountAssignmentLinkName', 'Currency', 'termEnd'], values=['purchaseValueDisplayCurrency', 'amoutn_outstanding'], aggfunc={'purchaseValueDisplayCurrency': sum, 'amoutn_outstanding': sum}).reset_index()\n",
    "\n",
    "data_Debt = add_in_currency_column(data_Debt, col_with_CCY='Currency', col_with_VAL='amoutn_outstanding', day_for_export=Today, CCY_to='USD')\n",
    "\n",
    "data_Debt['Entity_code'] = merge_Mapping(data_Debt, col='Entity')\n",
    "data_Debt['Entity_group'] = merge_SalesUnits(data_Debt, col='Entity_code', merge_col='ocpSegment')\n",
    "data_Debt['Counterparty_code'] = merge_Mapping(data_Debt, col='Counterparty')\n",
    "data_Debt['Counterparty_Group'] = merge_SalesUnits(data_Debt, col='Counterparty_code', merge_col='ocpSegment')\n",
    "\n",
    "data_Debt = Period(data_Debt, day_for_count=Today, col_with_date='termEnd')\n",
    "\n",
    "data_Debt['Holding'] = merge_SalesUnits(data_Debt, col='Entity_code', merge_col='holding')\n",
    "data_Debt['termEnd'] = data_Debt['termEnd'].fillna('_')\n",
    "# data_Debt = data_Debt.query('Holding == @Group').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Entity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Entity, Entity_code]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "manual1 = data_Debt.loc[data_Debt.Entity_code == 'External' ,['Entity', 'Entity_code']].drop_duplicates()\n",
    "manual2 = data_Debt.loc[data_Debt.Counterparty_code == 'External' ,['Counterparty', 'Counterparty_Group']].drop_duplicates()\n",
    "manual1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываю данные в output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']\n",
    "data_Debt = data_Debt.reindex(columns=(data_Debt.columns.tolist() + new_columns))\n",
    "data_Debt['Source'] = 'SAP'\n",
    "\n",
    "data = data_Debt[['Entity', 'Entity_group', 'Counterparty', 'Counterparty_Group', 'amoutn_outstanding', 'Currency', 'amount_USD_eq', 'termEnd', 'Days', 'Period', 'dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Entity_group</th>\n",
       "      <th>Counterparty</th>\n",
       "      <th>Counterparty_Group</th>\n",
       "      <th>amoutn_outstanding</th>\n",
       "      <th>Currency</th>\n",
       "      <th>amount_USD_eq</th>\n",
       "      <th>termEnd</th>\n",
       "      <th>Days</th>\n",
       "      <th>Period</th>\n",
       "      <th>dealClass1</th>\n",
       "      <th>dealClass2</th>\n",
       "      <th>instrumentOwner</th>\n",
       "      <th>dealSet</th>\n",
       "      <th>facility</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Sand Commodities</td>\n",
       "      <td>SUEK INT</td>\n",
       "      <td>AIM Capital Ltd</td>\n",
       "      <td>External</td>\n",
       "      <td>2.524600e+07</td>\n",
       "      <td>USD</td>\n",
       "      <td>2.524600e+07</td>\n",
       "      <td>2026-09-15</td>\n",
       "      <td>929.0</td>\n",
       "      <td>2Y+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black Sand Commodities</td>\n",
       "      <td>SUEK INT</td>\n",
       "      <td>Erglis Limited</td>\n",
       "      <td>External</td>\n",
       "      <td>1.302614e+09</td>\n",
       "      <td>RUB</td>\n",
       "      <td>1.428303e+07</td>\n",
       "      <td>2029-10-08</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2Y+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Entity Entity_group     Counterparty Counterparty_Group  \\\n",
       "0  Black Sand Commodities     SUEK INT  AIM Capital Ltd           External   \n",
       "1  Black Sand Commodities     SUEK INT   Erglis Limited           External   \n",
       "\n",
       "   amoutn_outstanding Currency  amount_USD_eq    termEnd    Days Period  \\\n",
       "0        2.524600e+07      USD   2.524600e+07 2026-09-15   929.0    2Y+   \n",
       "1        1.302614e+09      RUB   1.428303e+07 2029-10-08  2048.0    2Y+   \n",
       "\n",
       "   dealClass1  dealClass2  instrumentOwner  dealSet  facility Source  \n",
       "0         NaN         NaN              NaN      NaN       NaN    SAP  \n",
       "1         NaN         NaN              NaN      NaN       NaN    SAP  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(Output_file, sheet_name = Sheet_in_output_file, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на наличие тех же записей в Quantum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>Entity_group</th>\n",
       "      <th>counterparty</th>\n",
       "      <th>Counterparty_Group</th>\n",
       "      <th>amoutn outstanding</th>\n",
       "      <th>Currency</th>\n",
       "      <th>amount USD eq</th>\n",
       "      <th>termEnd</th>\n",
       "      <th>Days</th>\n",
       "      <th>Period</th>\n",
       "      <th>dealClass1</th>\n",
       "      <th>dealClass2</th>\n",
       "      <th>instrumentOwner</th>\n",
       "      <th>dealSet</th>\n",
       "      <th>facility</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRHRG</td>\n",
       "      <td>SAMSALES</td>\n",
       "      <td>Morgan Stanley BR</td>\n",
       "      <td>External</td>\n",
       "      <td>-8011.33</td>\n",
       "      <td>BRL</td>\n",
       "      <td>-1616.101732</td>\n",
       "      <td>2031-12-31</td>\n",
       "      <td>2862</td>\n",
       "      <td>2Y+</td>\n",
       "      <td>Loan</td>\n",
       "      <td>MM</td>\n",
       "      <td>EC_BORROWINGS</td>\n",
       "      <td>-</td>\n",
       "      <td>HRG Judicial recovery BRL</td>\n",
       "      <td>Quantum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRHRG</td>\n",
       "      <td>SAMSALES</td>\n",
       "      <td>Morgan Stanley BR</td>\n",
       "      <td>External</td>\n",
       "      <td>-9958.01</td>\n",
       "      <td>BRL</td>\n",
       "      <td>-2008.799688</td>\n",
       "      <td>2032-12-31</td>\n",
       "      <td>3228</td>\n",
       "      <td>2Y+</td>\n",
       "      <td>Loan</td>\n",
       "      <td>MM</td>\n",
       "      <td>EC_BORROWINGS</td>\n",
       "      <td>-</td>\n",
       "      <td>HRG Judicial recovery BRL</td>\n",
       "      <td>Quantum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity Entity_group       counterparty Counterparty_Group  \\\n",
       "0  BRHRG     SAMSALES  Morgan Stanley BR           External   \n",
       "1  BRHRG     SAMSALES  Morgan Stanley BR           External   \n",
       "\n",
       "   amoutn outstanding Currency  amount USD eq    termEnd  Days Period  \\\n",
       "0            -8011.33      BRL   -1616.101732 2031-12-31  2862    2Y+   \n",
       "1            -9958.01      BRL   -2008.799688 2032-12-31  3228    2Y+   \n",
       "\n",
       "  dealClass1 dealClass2 instrumentOwner dealSet                   facility  \\\n",
       "0       Loan         MM   EC_BORROWINGS       -  HRG Judicial recovery BRL   \n",
       "1       Loan         MM   EC_BORROWINGS       -  HRG Judicial recovery BRL   \n",
       "\n",
       "    Source  \n",
       "0  Quantum  \n",
       "1  Quantum  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantum_data_export = pd.read_excel('C:\\\\Users\\\\KlimovaAnnaA\\\\Documents\\\\MyFiles\\\\Projects\\\\OCP\\\\Quantum\\\\2024-03-21_EuroChem_quantum_Debt_Feb.xlsx')\n",
    "quantum_data_export.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_data_export['E_Cgroup'] = quantum_data_export.entity + quantum_data_export.Counterparty_Group + quantum_data_export.Currency + quantum_data_export.termEnd.astype(str) + quantum_data_export['amoutn outstanding'].abs().astype(str)\n",
    "data_Debt['E_Cgroup'] = data_Debt.Entity_code + data_Debt.Counterparty_Group + data_Debt.Currency + data_Debt.termEnd.astype(str) + data_Debt.amoutn_outstanding.abs().astype(str)\n",
    "\n",
    "iner_list = list(set(data_Debt['E_Cgroup']).intersection(set(quantum_data_export.E_Cgroup)))\n",
    "\n",
    "SAP_iner = data_Debt[data_Debt.E_Cgroup.isin(iner_list)]\n",
    "Quantum_iner = quantum_data_export[quantum_data_export.E_Cgroup.isin(iner_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 23), (16, 17))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iner_list_2 = SAP_iner.index.tolist()\n",
    "\n",
    "SAP_iner = data_Debt[data_Debt.index.isin(iner_list_2)]\n",
    "data_Debt_not_iner = data_Debt[~data_Debt.index.isin(iner_list_2)]\n",
    "\n",
    "SAP_iner.shape, Quantum_iner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAP_iner = SAP_iner[['Entity', 'Entity_group', 'Counterparty', 'Counterparty_Group', 'amoutn_outstanding', 'Currency', 'amount_USD_eq', 'termEnd', 'Days', 'Period', 'dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']]\n",
    "data_Debt_not_iner = data_Debt_not_iner[['Entity', 'Entity_group', 'Counterparty', 'Counterparty_Group', 'amoutn_outstanding', 'Currency', 'amount_USD_eq', 'termEnd', 'Days', 'Period', 'dealClass1','dealClass2','instrumentOwner','dealSet','facility','Source']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Debt_not_iner.to_excel(Output_file, sheet_name=Sheet_in_output_file, index=False)\n",
    "new_list(SAP_iner, Output_file, 'Inersection')\n",
    "new_list(quantum_data_export, Output_file, 'Debt_Quantum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка встречных требований:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_8776\\3230643493.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_E_to_C['Index_copy'] = data_E_to_C.index\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_8776\\3230643493.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_E_to_C['concat_col_EC'] = data_E_to_C[['Entity_code', 'Counterparty_code', 'Currency',  'amoutn_outstanding', 'termEnd']].astype(str).agg('.'.join, axis=1)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_8776\\3230643493.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_E_to_C['concat_col_CE'] = data_E_to_C[['Counterparty_code', 'Entity_code', 'Currency',  'amoutn_outstanding', 'termEnd']].astype(str).agg('.'.join, axis=1)\n"
     ]
    }
   ],
   "source": [
    "index_dataDebt_to_print = []\n",
    "\n",
    "# Фильт по Counterparty_Group - только внутригрупповые\n",
    "data_E_to_C = data_Debt.query('Counterparty_Group != \"External\"')\n",
    "data_E_to_C['Index_copy'] = data_E_to_C.index\n",
    "\n",
    "# Кокатенация значений\n",
    "data_E_to_C['concat_col_EC'] = data_E_to_C[['Entity_code', 'Counterparty_code', 'Currency',  'amoutn_outstanding', 'termEnd']].astype(str).agg('.'.join, axis=1)\n",
    "data_E_to_C['concat_col_CE'] = data_E_to_C[['Counterparty_code', 'Entity_code', 'Currency',  'amoutn_outstanding', 'termEnd']].astype(str).agg('.'.join, axis=1)\n",
    "\n",
    "# Данные с повторяющимися значениями\n",
    "doubles_data = data_E_to_C[data_E_to_C.concat_col_EC.isin(data_E_to_C.concat_col_CE)]\n",
    "doubles_data = doubles_data.sort_values(by=['Currency',  'amoutn_outstanding', 'termEnd'])\n",
    "# Проверка на отсутсвие необходимости суммировать значения amoutn_outstanding\n",
    "group_data = data_E_to_C.pivot_table(index=['Entity_code', 'Counterparty_code','accountAssignmentLinkName', 'Currency', 'termEnd'], values='Index_copy', aggfunc={'Index_copy': list}, fill_value=day).reset_index()\n",
    "group_data['Index_count'] = group_data['Index_copy'].apply(len)\n",
    "assert group_data.Index_count.unique().tolist() == [1]\n",
    "# Проверка наличия пары у кадого значения\n",
    "group_data = doubles_data.pivot_table(index=['Currency', 'amoutn_outstanding', 'termEnd'], values='Index_copy', aggfunc={'Index_copy': list}, fill_value=day).reset_index()\n",
    "group_data['Index_count'] = group_data['Index_copy'].apply(len)\n",
    "assert group_data.Index_count.unique().tolist() == [2]\n",
    "\n",
    "# В список index_dataDebt_to_print добавлена только одна запись из равной пары\n",
    "group_data['index_to_print'] = group_data['Index_copy'].str[0]\n",
    "index_to_print_list = group_data.index_to_print.tolist()\n",
    "index_dataDebt_to_print += index_to_print_list\n",
    "# Проверка, что взята ровно половина повторяющихся данных\n",
    "assert len(index_dataDebt_to_print) == len(doubles_data)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не совпадать значения могу из-за: 1. ошибок в Mapping, 2. неравных значений amount, 3. если у них нет пары"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert data_E_to_C.shape[0] == doubles_data.shape[0] + not_doubles_data.shape[0]\n",
    "\n",
    "# doubles_data.to_excel('2024-03-27_SAP_Debt_Feb.xlsx', sheet_name='Douples', index=False) # название файла\n",
    "# new_list(not_doubles_data, '2024-03-27_SAP_Debt_Feb.xlsx', sheet_name='Not_douples') # название файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Поиск оишбок в Mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные с НЕповторяющимися значениями\n",
    "not_doubles_data = data_E_to_C[~data_E_to_C.concat_col_EC.isin(data_E_to_C.concat_col_CE)]\n",
    "not_doubles_data = not_doubles_data.sort_values(by=['Currency',  'amoutn_outstanding', 'termEnd'])\n",
    "\n",
    "group_data = not_doubles_data.groupby(['Currency', 'amoutn_outstanding', 'termEnd'], as_index=False).agg({'Index_copy': list})\n",
    "group_data['Index_count'] = group_data['Index_copy'].apply(len)\n",
    "\n",
    "if len(group_data.loc[group_data.Index_count>1, 'Index_copy'].values) != 0:\n",
    "    in_doubles = list(np.concatenate(group_data.loc[group_data.Index_count>1, 'Index_copy'].values, axis = 0))\n",
    "    not_doubles_data_manual = not_doubles_data[not_doubles_data['Index_copy'].isin(in_doubles)]\n",
    "    not_doubles_data_manual_print = not_doubles_data_manual[['Entity', 'Entity_code', 'Counterparty', 'Counterparty_code']]\n",
    "    print(not_doubles_data_manual)\n",
    "    # new_list(not_doubles_data_manual_print, '2024-03-27_SAP_Debt_Feb.xlsx', sheet_name='Not_douples_manual') # название файла\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Поиск неравных значений amount для равных пар:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Currency    termEnd  amoutn_outstanding       Index_copy  Index_count\n",
      "1      RUB 2024-06-30        2.445398e+08         [67, 93]            2\n",
      "0      RUB 2024-03-21        3.363447e+09  [214, 210, 447]            3\n",
      "3      RUB 2028-07-12        9.236379e+09        [395, 12]            2\n",
      "2      RUB 2028-06-14        1.165192e+10   [404, 402, 76]            3\n"
     ]
    }
   ],
   "source": [
    "not_doubles_data['concat_col2_EC'] = not_doubles_data[['Entity_code', 'Counterparty_code', 'Currency','termEnd']].astype(str).agg('.'.join, axis=1)\n",
    "not_doubles_data['concat_col2_CE'] = not_doubles_data[['Counterparty_code', 'Entity_code', 'Currency','termEnd']].astype(str).agg('.'.join, axis=1)\n",
    "\n",
    "# Данные с повторяющимися значениями\n",
    "doubles_data2 = not_doubles_data[not_doubles_data.concat_col2_EC.isin(not_doubles_data.concat_col2_CE)]\n",
    "doubles_data2 = doubles_data2.sort_values(by=['Currency', 'termEnd'])\n",
    "group_data = doubles_data2.groupby(['Currency', 'termEnd'], as_index=False).agg({'amoutn_outstanding': 'mean', 'Index_copy': list}).sort_values(['Currency', 'amoutn_outstanding', 'termEnd'])\n",
    "group_data['Index_count'] = group_data['Index_copy'].apply(len)\n",
    "print(group_data)\n",
    "# в выборке присутсвуют только двухстрочне значения\n",
    "# assert group_data.Index_count.unique().tolist() == [2]\n",
    "\n",
    "### ЗДЕСЬ МОЖНО ВЫБРАТЬ СРЕДНЕЕ \n",
    "\n",
    "# В список index_dataDebt_to_print добавлена только одна запись из равной пары\n",
    "group_data['index_to_print'] = group_data['Index_copy'].str[-1]\n",
    "index_to_print_list = group_data.index_to_print.tolist()\n",
    "index_dataDebt_to_print += index_to_print_list\n",
    "\n",
    "# Данные с НЕповторяющимися значениями\n",
    "data = not_doubles_data[~not_doubles_data.concat_col2_EC.isin(not_doubles_data.concat_col2_CE)]\n",
    "data = data.sort_values(['Currency',  'amoutn_outstanding', 'termEnd'])\n",
    "index_to_print_list = data.Index_copy.tolist()\n",
    "index_dataDebt_to_print += index_to_print_list\n",
    "\n",
    "assert sum(group_data.Index_count.tolist()) == not_doubles_data.shape[0] - len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dataDebt_to_print.index(447)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_8776\\1431249174.py:11: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  data_Debt_after_cleaning.to_excel(file, 'Debt')\n"
     ]
    }
   ],
   "source": [
    "assert len(index_dataDebt_to_print) < len(data_Debt)\n",
    "index_dataDebt_to_print = list(set(index_dataDebt_to_print))\n",
    "\n",
    "file = '2024-03-27_SAP_Debt_Feb.xlsx'\n",
    "\n",
    "data_Debt_after_cleaning = data_Debt.loc[index_dataDebt_to_print, :]\n",
    "# Возвращение знака amoutn_outstanding\n",
    "data_Debt_after_cleaning.amoutn_outstanding = data_Debt_after_cleaning.amoutn_outstanding * np.sign(data_Debt_after_cleaning.purchaseValueDisplayCurrency)\n",
    "# Слеивание с данными внешних требований\n",
    "data_Debt_after_cleaning = pd.concat([data_Debt_after_cleaning, data_Debt.query('Counterparty_Group == \"External\"')])\n",
    "data_Debt_after_cleaning.to_excel(file, 'Debt')\n",
    "new_list(data_Debt, file, 'Debt_before', index=True)\n",
    "new_list(doubles_data, file,'Douples', index=True)\n",
    "new_list(not_doubles_data, file,'Not_douples', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "214",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\KlimovaAnnaA\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 214",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Debt\\Debt_SUEK.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KlimovaAnnaA/Documents/MyFiles/Projects/OCP/Debt/Debt_SUEK.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_Debt_after_cleaning\u001b[39m.\u001b[39;49mloc[\u001b[39m214\u001b[39;49m, :]\n",
      "File \u001b[1;32mc:\\Users\\KlimovaAnnaA\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1185\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1185\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1187\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\KlimovaAnnaA\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1369\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1368\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1369\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1371\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1372\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32mc:\\Users\\KlimovaAnnaA\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1066\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[0;32m   1063\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m   1064\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m-> 1066\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m   1068\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[0;32m   1072\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KlimovaAnnaA\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1432\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\KlimovaAnnaA\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1381\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\KlimovaAnnaA\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4295\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4293\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[0;32m   4294\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4295\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4297\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m   4298\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[1;32mc:\\Users\\KlimovaAnnaA\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 214"
     ]
    }
   ],
   "source": [
    "data_Debt_after_cleaning.loc[214, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
