{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Today = '2024-03-31'\n",
    "\n",
    "print_Deals = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\KlimovaAnnaA\\\\Documents\\\\MyFiles\\\\Projects\\\\OCP\")\n",
    "from Defs import merge_SalesUnits\n",
    "from Defs import merge_Mapping\n",
    "from Defs import Period\n",
    "from Defs import new_list\n",
    "from Defs import export_from_RISKCUSTOM\n",
    "from Defs import add_in_currency_column\n",
    "from Defs import concat_columns\n",
    "from Defs import export_from_WHWEEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:80: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"select * from RISKACCESS.\"sapDeals\" where \"reportDate\" = TO_DATE('{Today}', 'YYYY-MM-DD') \"\"\"\n",
    "data_ex_deals_export = export_from_RISKCUSTOM(query)\n",
    "\n",
    "query = f\"\"\"select * from RISKACCESS.\"sapIcDeals\" where \"reportDate\" = TO_DATE('{Today}', 'YYYY-MM-DD') \"\"\"\n",
    "data_in_deals_export = export_from_RISKCUSTOM(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>##batch_id</th>\n",
       "      <th>##deleted</th>\n",
       "      <th>##inserted</th>\n",
       "      <th>##origin_name</th>\n",
       "      <th>pricingKey</th>\n",
       "      <th>conditionItemNumber</th>\n",
       "      <th>conditionType</th>\n",
       "      <th>reportDate</th>\n",
       "      <th>conditionGroup</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>ecvnar</th>\n",
       "      <th>invoiced</th>\n",
       "      <th>cashed</th>\n",
       "      <th>billingTypeId</th>\n",
       "      <th>billingType</th>\n",
       "      <th>producerId</th>\n",
       "      <th>producerName</th>\n",
       "      <th>dealDate</th>\n",
       "      <th>deliveryLotToleranceOption</th>\n",
       "      <th>priceFixingDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [##batch_id, ##deleted, ##inserted, ##origin_name, pricingKey, conditionItemNumber, conditionType, reportDate, conditionGroup, id, itemNumber, subItemNumber, documentType, contractId, addendum, pnlCode, buyerId, buyerName, sellerId, sellerName, counterpartyId, counterpartyName, creationDate, dealTypeId, dealTypeName, dealStatusId, dealStatusName, companyCode, companyName, tradingContractMaterialId, tradingContractMaterialName, tradingPurposeId, tradingPurposeName, productTypeId, productTypeName, tradeRegionId, tradeRegionName, destinationCountryId, destinationCountryName, meansOfTransportId, meansOfTransportName, deliveryPeriodFrom, deliveryPeriodTo, deliveryLotTonnageMin, deliveryLotTonnageMax, deliveryLotTolerance, deliveryLotToleranceUnit, tradingOfficeId, tradingOfficeName, traderId, traderName, createdById, createdByName, productId, productName, titleTransferEventId, titleTransferEventName, titleTransferDate, titleTransferFlag, salesProgramId, salesProgramName, incoterms1, incotermsBaseId, incotermsBase, dispatchMonth, deliveryMonth, billingDate, deliveryDate, etaDate, loadingPort1Id, loadingPort1Name, loadingPort2Id, loadingPort2Name, dischargePort1Id, dischargePort1Name, dischargePort2Id, dischargePort2Name, dischargePort3Id, dischargePort3Name, loadingStationId, loadingStationName, deliveryStationId, deliveryStationName, crossBorderStationId, crossBorderStationName, laycanDateFrom, laycanDateTo, loadPortCountryId, loadPortCountryName, dischargePortCountryId, dischargePortCountryName, routeId, routeName, vesselId, vesselName, vesselClass, priceTypeId, priceTypeName, ccvBasis, ccv, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 163 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_data_in_deals\n",
    "data_in_deals_export.query(\"dealStatusName != 'Cancelled' & invoiced == 'Y' & deliveryPeriodTo > @Today\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:80: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:80: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:80: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:80: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:80: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n",
      "C:\\Users\\KlimovaAnnaA\\Documents\\MyFiles\\Projects\\OCP\\Defs.py:80: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_export = pd.read_sql(query, con=connection)\n"
     ]
    }
   ],
   "source": [
    "work_data_list = [data_ex_deals_export, data_in_deals_export]\n",
    "\n",
    "for work_data_index in range(len(work_data_list)):\n",
    "    data_work = work_data_list[work_data_index]\n",
    "    data_work = data_work.query(\"dealStatusName != 'Cancelled' & invoiced == 'Y' & deliveryPeriodTo > @Today\").reset_index(drop=True)\n",
    "    data_work[['sellerName', 'buyerName']] = data_work[['sellerName', 'buyerName']].fillna('')\n",
    "    data_work['Counterparty'] = data_work['sellerName'] + data_work['buyerName']\n",
    "    data_work.loc[data_work['actualQuantity'].isna(), 'actualQuantity'] = data_work.loc[data_work['actualQuantity'].isna(), 'BLTonnage']\n",
    "    if work_data_index == 0:\n",
    "        price_col = 'conditionPrice'\n",
    "    else:\n",
    "        price_col = 'price'\n",
    "    data_work['Sum_money'] = data_work['actualQuantity'] * data_work[price_col]\n",
    "    data_work.loc[data_work.dealTypeName == 'Purchasing Deal', 'actualQuantity'] = data_work.actualQuantity.abs()\n",
    "    data_work.loc[data_work.dealTypeName == 'Purchasing Deal', 'Sum_money'] = -1 * data_work.Sum_money.abs()\n",
    "    data_work.loc[data_work.dealTypeName == 'Sales Deal', 'actualQuantity'] = -1 * data_work.actualQuantity.abs()\n",
    "    data_work.loc[data_work.dealTypeName == 'Sales Deal', 'Sum_money'] = data_work.Sum_money.abs()\n",
    "    data_work['CompCode'] = merge_Mapping(data_work, col='companyName')\n",
    "    data_work['Business_segment'] = merge_SalesUnits(data_work, col='CompCode', merge_col='ocpSegment')\n",
    "    data_work['Cpty_Code'] = merge_Mapping(data_work, col='Counterparty')\n",
    "    data_work['Cpty_segment'] = merge_SalesUnits(data_work, col='Cpty_Code', merge_col='ocpSegment').fillna('External')\n",
    "    data_work = Period(data_work, day_for_count=Today, col_with_date='deliveryPeriodTo')\n",
    "    data_work['holding'] = merge_SalesUnits(data_work, 'CompCode', merge_col='holding')\n",
    "\n",
    "    data_for_print = data_work[['productTypeName', 'companyName', 'Business_segment', 'Counterparty',  'Cpty_segment', 'currency', 'actualQuantity', 'Sum_money', 'deliveryPeriodTo', 'Days', 'Period']]\n",
    "\n",
    "    if work_data_index == 0:\n",
    "        work_data_ex_deals = data_for_print\n",
    "    else:\n",
    "        work_data_in_deals = data_for_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_9880\\3230448435.py:9: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  work_data_ex_deals_group.to_excel(Output_file_ex, Sheet_in_output_file, index=False)\n",
      "C:\\Users\\KlimovaAnnaA\\AppData\\Local\\Temp\\ipykernel_9880\\3230448435.py:10: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  work_data_in_deals_group.to_excel(Output_file_in, Sheet_in_output_file, index=False)\n"
     ]
    }
   ],
   "source": [
    "Sheet_in_output_file = 'Deals'\n",
    "\n",
    "if print_Deals == True:\n",
    "    for group in ['EUROCHEM', 'SUEK']:\n",
    "        work_data_ex_deals_group = work_data_ex_deals[work_data_ex_deals.holding == group]\n",
    "        work_data_in_deals_group = work_data_in_deals[work_data_in_deals.holding == group]\n",
    "        Output_file_ex = \"_\".join([str(date.today()), group, 'EX_Deals.xlsx'])\n",
    "        Output_file_in = \"_\".join([str(date.today()), group, 'IN_Deals.xlsx'])\n",
    "        work_data_ex_deals_group.to_excel(Output_file_ex, Sheet_in_output_file, index=False)\n",
    "        work_data_in_deals_group.to_excel(Output_file_in, Sheet_in_output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
